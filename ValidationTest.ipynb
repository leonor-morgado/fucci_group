{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from FUCCIDataLoader import FUCCIDataset\n",
    "from UnetModel import UNet\n",
    "from Train import train\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "\n",
    "train_dataset = FUCCIDataset(root_dir=\"leonor\", source_channels=0, target_channels=(0, 1), transform=transforms.RandomCrop(256)) #Do we need to crop? Guess also some data augmentation here would be nice\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=8) \n",
    "\n",
    "load_path = \"/group/dl4miacourse/projects/FUCCI/leonor/Models/model1.pt\"\n",
    "\n",
    "\n",
    "### Declare the U-Net and its parameters\n",
    "\n",
    "model = UNet(depth=2, in_channels=1, out_channels=2)\n",
    "model.load_state_dict(torch.load(load_path))\n",
    "\n",
    "#TODO tensoboard logs\n",
    "#logger = SummaryWriter(f\"unet_runs/{model_name}\")\n",
    "\n",
    "\n",
    "        \n",
    "#After confirming that runs at least one epoch, go to terminal and nvdia-smi to be sure it's running in the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run validation after training epoch\n",
    "def validate(\n",
    "    model,\n",
    "    loader,\n",
    "    loss_function,\n",
    "    #metric,\n",
    "    step=None,\n",
    "    tb_logger=None,\n",
    "    device=None,\n",
    "):\n",
    "    if device is None:\n",
    "        # You can pass in a device or we will default to using\n",
    "        # the gpu. Feel free to try training on the cpu to see\n",
    "        # what sort of performance difference there is\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "\n",
    "    # set model to eval mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # running loss and metric values\n",
    "    val_loss = 0\n",
    "    #val_metric = 0\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    pred_list = []\n",
    "\n",
    "    # disable gradients during validation\n",
    "    with torch.no_grad():\n",
    "        # iterate over validation loader and update loss and metric values\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            prediction = model(x)\n",
    "            # We *usually* want the target to be the same type as the prediction\n",
    "            # however this is very dependent on your choice of loss function and\n",
    "            # metric. If you get errors such as \"RuntimeError: Found dtype Float but expected Short\"\n",
    "            # then this is where you should look.\n",
    "            if y.dtype != prediction.dtype:\n",
    "                y = y.type(prediction.dtype)\n",
    "            val_loss += loss_function(prediction, y).item()\n",
    "            #val_metric += metric(prediction > 0.5, y).item()\n",
    "\n",
    "            x_list.append(x.cpu())\n",
    "            y_list.append(y.cpu())\n",
    "            pred_list.append(prediction.cpu())\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # normalize loss and metric\n",
    "    val_loss /= len(loader)\n",
    "    #val_metric /= len(loader)\n",
    "\n",
    "    print(\n",
    "        \"\\nValidate: Average loss: {:.4f}\\n\".format(\n",
    "            val_loss\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return x_list, y_list, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function: torch.nn.Module = torch.nn.MSELoss()\n",
    "x_list, y_list, pred_list = validate(model, train_loader, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "batch_idx = np.random.randint(len(x_list))\n",
    "item_idx = np.random.randint(len(x_list[batch_idx]))\n",
    "print(batch_idx, item_idx)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(15,3),ncols=5)\n",
    "ax[0].imshow(x_list[batch_idx][item_idx,0])\n",
    "ax[1].imshow(y_list[batch_idx][item_idx,0])\n",
    "ax[2].imshow(y_list[batch_idx][item_idx,1])\n",
    "ax[3].imshow(pred_list[batch_idx][item_idx,0])\n",
    "ax[4].imshow(pred_list[batch_idx][item_idx,1])\n",
    "\n",
    "plt.savefig(\"p.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
